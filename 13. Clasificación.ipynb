{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de patrones: Clasificación\n",
    "### Ramón Soto C. [(rsotoc@moviquest.com)](mailto:rsotoc@moviquest.com/)\n",
    "![ ](images/blank.png)\n",
    "![agents](images/binary_data_under_a_magnifying.jpg)\n",
    "[ver en nbviewer](http://nbviewer.ipython.org/github/rsotoc/pattern-recognition/blob/master/Clasificación%20I.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo de la calidad de clasificación\n",
    "\n",
    "\n",
    "## La *Exactitud*\n",
    "\n",
    "La forma más común de evaluar la calidad de un sistema de clasificación automática es a través de su *exactitud* sobre datos conocidos, esto es, la tasa de aciertos $(N_c)$ contra el total de intentos $(N_T)$:\n",
    "\n",
    "$$AC = \\frac{N_c}{N_T}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos la exactitud para un caso simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el ambiente\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sys\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from sklearn import cluster\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=2, suppress=True) # Cortar la impresión de decimales a 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puesto que necesitamos datos previmente clasificados para entrenar el clasificador, utilizamos k-medias para asignar valores de clase a cada dato:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70.28</td>\n",
       "      <td>42.125</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>56.750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.00</td>\n",
       "      <td>2.500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.64</td>\n",
       "      <td>11.667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82.00</td>\n",
       "      <td>58.800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>86.00</td>\n",
       "      <td>77.265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80.00</td>\n",
       "      <td>85.500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68.20</td>\n",
       "      <td>62.440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>72.00</td>\n",
       "      <td>88.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>74.00</td>\n",
       "      <td>80.604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>91.72</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>77.69</td>\n",
       "      <td>13.167</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>79.80</td>\n",
       "      <td>71.200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>87.10</td>\n",
       "      <td>75.391</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.00</td>\n",
       "      <td>80.854</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.00</td>\n",
       "      <td>59.933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>96.00</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>86.00</td>\n",
       "      <td>89.583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.00</td>\n",
       "      <td>76.250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.00</td>\n",
       "      <td>90.625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100.00</td>\n",
       "      <td>95.063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>87.00</td>\n",
       "      <td>62.556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>79.00</td>\n",
       "      <td>82.458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.00</td>\n",
       "      <td>75.919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.00</td>\n",
       "      <td>76.875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>73.46</td>\n",
       "      <td>83.531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>92.00</td>\n",
       "      <td>87.563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>77.00</td>\n",
       "      <td>84.375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>70.80</td>\n",
       "      <td>35.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>92.60</td>\n",
       "      <td>66.875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         A       B  Class\n",
       "0    70.28  42.125      2\n",
       "1     0.00  56.750      1\n",
       "2    79.00   2.500      2\n",
       "3    75.64  11.667      2\n",
       "4    82.00  58.800      0\n",
       "5    86.00  77.265      0\n",
       "6    80.00  85.500      0\n",
       "7    68.20  62.440      0\n",
       "8    72.00  88.000      0\n",
       "9    74.00  80.604      0\n",
       "10   91.72   0.000      2\n",
       "11   77.69  13.167      2\n",
       "12   79.80  71.200      0\n",
       "13   87.10  75.391      0\n",
       "14    0.00  80.854      1\n",
       "15    0.00  59.933      1\n",
       "16   96.00   5.000      2\n",
       "17   86.00  89.583      0\n",
       "18    0.00  76.250      1\n",
       "19    0.00  90.625      1\n",
       "20  100.00  95.063      0\n",
       "21   87.00  62.556      0\n",
       "22   79.00  82.458      0\n",
       "23    0.00  75.919      1\n",
       "24    0.00  76.875      1\n",
       "25   73.46  83.531      0\n",
       "26   92.00  87.563      0\n",
       "27   77.00  84.375      0\n",
       "28   70.80  35.000      2\n",
       "29   92.60  66.875      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Leer los datos de archivo, separar training y test y calcular \"prototipos de clase\"\n",
    "df = pd.read_csv(\"Data sets/datosProm.csv\", names = ['A', 'B'])\n",
    "\n",
    "# Clasificar con k-means\n",
    "num_clusters = 3\n",
    "k_means = cluster.KMeans(n_clusters=num_clusters, init='random')\n",
    "k_means.fit(df)\n",
    "df[\"Class\"] = k_means.labels_\n",
    "\n",
    "# Desplegar los datos clasificados\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, separamos los datos en datos de entrenamiento y datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de entrenamiento:\n",
      "         A       B  Class\n",
      "17   86.00  89.583      0\n",
      "27   77.00  84.375      0\n",
      "7    68.20  62.440      0\n",
      "12   79.80  71.200      0\n",
      "4    82.00  58.800      0\n",
      "23    0.00  75.919      1\n",
      "6    80.00  85.500      0\n",
      "20  100.00  95.063      0\n",
      "9    74.00  80.604      0\n",
      "11   77.69  13.167      2\n",
      "29   92.60  66.875      0\n",
      "19    0.00  90.625      1\n",
      "21   87.00  62.556      0\n",
      "0    70.28  42.125      2\n",
      "8    72.00  88.000      0\n",
      "28   70.80  35.000      2\n",
      "3    75.64  11.667      2\n",
      "25   73.46  83.531      0\n",
      "24    0.00  76.875      1\n",
      "10   91.72   0.000      2\n",
      "\n",
      "Datos de Prueba:\n",
      "       A       B  Class\n",
      "15   0.0  59.933      1\n",
      "5   86.0  77.265      0\n",
      "22  79.0  82.458      0\n",
      "26  92.0  87.563      0\n",
      "18   0.0  76.250      1\n",
      "14   0.0  80.854      1\n",
      "13  87.1  75.391      0\n",
      "2   79.0   2.500      2\n",
      "16  96.0   5.000      2\n",
      "1    0.0  56.750      1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Seleccionar y desplegar datos de entrenamiento/prueba\n",
    "df_train, df_test = train_test_split(df, test_size=0.33, random_state=3)\n",
    "print(\"Datos de entrenamiento:\\n{}\\n\\nDatos de Prueba:\\n{}\".format(df_train, df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos un clasificador de k-vecinos próximos para clasificar los datos de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida esperada: [1 0 0 0 1 1 0 2 2 1]\n",
      "\n",
      "Salida obtenida: [1 0 0 0 1 1 0 2 2 1]\n",
      "\n",
      "Exactitud: 1.0\n",
      "\n",
      "Exactitud porcentual: 100.0\n",
      "\n",
      "Tasa de error: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Crear y entrenar un artefacto KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "train_output = df_train[[\"Class\"]].values.ravel()\n",
    "neigh.fit(df_train[[\"A\", \"B\"]], train_output)\n",
    "\n",
    "# Clasificar los datos de prueba e imprimir los resultados\n",
    "test_expected_output = df_test[[\"Class\"]].values.ravel()\n",
    "print(\"Salida esperada:\", test_expected_output)\n",
    "test_automatic_output = neigh.predict(df_test[[\"A\", \"B\"]])\n",
    "print(\"\\nSalida obtenida:\", test_automatic_output)\n",
    "\n",
    "# Contabilizar casos correctos\n",
    "correct = 0\n",
    "for i in range(len(test_expected_output)):\n",
    "    if test_automatic_output[i] == test_expected_output[i]:\n",
    "        correct += 1\n",
    "\n",
    "# Calcular la exactitud\n",
    "accuracy = correct / len(test_expected_output)\n",
    "print(\"\\nExactitud:\", accuracy)\n",
    "print(\"\\nExactitud porcentual:\", accuracy * 100)\n",
    "print(\"\\nTasa de error:\", (1 - accuracy) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos ahora con los datos del \"Pima Indians Diabetes Dataset\" (utilizamos semilla fija para reproducibilidad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Salida esperada: [1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0\n",
      " 1 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 0 1\n",
      " 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1]\n",
      "\n",
      "Salida obtenida: [0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 1 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1\n",
      " 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1]\n",
      "\n",
      "Exactitud: 0.7615384615384615\n",
      "\n",
      "Exactitud porcentual: 76.15384615384615\n",
      "\n",
      "Tasa de error: 23.84615384615385\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df_pid = pd.read_csv(\"Data sets/Pima Indian Data Set/pima-indians-diabetes.data\", \n",
    "                 names = ['emb', 'gl2h', 'pad', 'ept', 'is2h', 'imc', 'fpd', 'edad', 'class'])\n",
    "df_pid.loc[df_pid['pad'] == 0,'pad'] = np.nan\n",
    "df_pid.loc[df_pid['ept'] == 0,'ept'] = np.nan\n",
    "df_pid.loc[df_pid['is2h'] == 0,'is2h'] = np.nan\n",
    "df_pid.loc[df_pid['imc'] == 0,'imc'] = np.nan\n",
    "df_pid = df_pid.dropna()\n",
    "\n",
    "df_train2, df_test2 = train_test_split(df_pid, test_size=0.33, random_state=0)\n",
    "\n",
    "# Crear y entrenar un artefacto KNeighborsClassifier\n",
    "neigh2 = KNeighborsClassifier(n_neighbors=5)\n",
    "train_output2 = df_train2[[\"class\"]].values.ravel()\n",
    "neigh2.fit(df_train2[['emb', 'gl2h', 'pad', 'ept', 'is2h', 'imc', 'fpd', 'edad']], \n",
    "           train_output2)\n",
    "\n",
    "# Clasificar los datos de prueba e imprimir los resultados\n",
    "test_expected_output2 = df_test2[[\"class\"]].values.ravel()\n",
    "print(\"\\nSalida esperada:\", test_expected_output2)\n",
    "test_automatic_output2 = neigh2.predict(\n",
    "    df_test2[['emb', 'gl2h', 'pad', 'ept', 'is2h', 'imc', 'fpd', 'edad']])\n",
    "print(\"\\nSalida obtenida:\", test_automatic_output2)\n",
    "\n",
    "# Contabilizar casos correctos\n",
    "correct = 0\n",
    "for i in range(len(test_expected_output2)):\n",
    "    if test_automatic_output2[i] == test_expected_output2[i]:\n",
    "        correct += 1\n",
    "\n",
    "# Calcular la exactitud\n",
    "accuracy2 = correct / len(test_expected_output2)\n",
    "print(\"\\nExactitud:\", accuracy2)\n",
    "print(\"\\nExactitud porcentual:\", accuracy2 * 100)\n",
    "print(\"\\nTasa de error:\", (1 - accuracy2) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque la exactitud es una buena medida de calidad de un clasificador, tiene algunos inconvenientes en problemas reales, debido a que oculta detalles que, en muchos casos, son fundamentales.\n",
    "\n",
    "* El problema más importante ocurre en datos *no balanceados*: Si una clase tiene muchos más datos que las demás clases, los aciertos en la clase numerosa oculta los errores de las otras clases. Supongamos un problema en el que una clase tiene el 99% de los datos, entonces, mientras no haya errores en esta clase, el error se mantendrá por abajo del 1%. En casos reales, es frecuente tener datos no bien balancedos. Esto ocurre con la mayoría de las enfermedades; incluso la diabetes tiene una frecuencia inferior al 10%, por lo tanto, mientras nuestro sistema no diagnostique como dibético a alguien sano, el error se mantendrá inferior al 10%. La Progeria de Hutchinson–Gilford tiene una incidencia inferior a 1 en 8 millones. Otro caso semejante sería la identificación de terroristas en un aeropuerto o la identificación de fraudes en hipotecas (inferior al 1%). \n",
    "\n",
    "* Cuando hay más de dos clases, la exactitud nos da una estimación del error promedio en todas las clases, pero oculta el error en clases específicas.\n",
    "\n",
    "* Un tercer problemas es el costo del error; este problema surge de la diferencia entre el error cometido al considerar como positivo un caso negativo y el error al calificar como negativo un caso positivo. Clasificar como sano a un paciente enfermo, por ejemplo, suele ser más delicado que clasificar como enfermo a un paciente sano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La *Matriz de confusión*\n",
    "\n",
    "Una matriz de confusión es una matriz de tamaño $N\\times N$, siendo $N$ el número de clases. Esta matriz compara la distribución real de elementos por clase contra las clases identificadas por el algoritmo. En esta matriz, cada renglón presenta la cantidad de elementos pertenecientes a una clase (valor real/esperado) mientras que cada columna en el renglón representa la cantidad de elementos en una de las clases (o viceversa.\n",
    "\n",
    "Consideremos la matriz de confusión para el ejemplo de calificaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0]\n",
      " [0 4 0]\n",
      " [0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(test_expected_output, test_automatic_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso: \n",
    "\n",
    "* Existen 4 elementos pertenecientes a la clase '0', todos clasificados (correctamente) en la clase '0'.\n",
    "* Existen 2 elementos pertenecientes a la clase '1', todos clasificados (correctamente) en la clase '1'.\n",
    "* Existen 4 elementos pertenecientes a la clase '2', todos clasificados (correctamente) en la clase '2'.\n",
    "\n",
    "Los elementos clasificados correctamente se localizan sobre la diagonal de la matriz de confusión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos ahora la matriz de confusión para los datos de diabetes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de prueba: 130\n",
      "Datos de prueba con class=0: 80\n",
      "Datos de prueba con class=1: 50\n",
      "\n",
      "Exactitud porcentual: 76.15384615384615\n",
      "\n",
      "Matriz de confusión\n",
      " [[74  6]\n",
      " [25 25]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Datos de prueba:\", len(df_test2))\n",
    "print(\"Datos de prueba con class=0:\", len(df_test2[df_test2[\"class\"]==0]))\n",
    "print(\"Datos de prueba con class=1:\", len(df_test2[df_test2[\"class\"]==1]))\n",
    "print(\"\\nExactitud porcentual:\", accuracy2 * 100)\n",
    "print(\"\\nMatriz de confusión\\n\", \n",
    "      confusion_matrix(test_expected_output2, test_automatic_output2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso: \n",
    "\n",
    "* Existen 80 elementos pertenecientes a la clase '0', de los cuales, sólo 74 fueron clasificados correctamente, mientras que 6 fueron clasificados como pertenecientes a la clase '1'.\n",
    "* Existen 50 elementos pertenecientes a la clase '1' y sólo 25 de ellos clasificados correctamente.\n",
    "\n",
    "Nuevamente, los elementos clasificados correctamente se localizan sobre la diagonal de la matriz de confusión. \n",
    "\n",
    "Es sobresaliente que mientras que la exactitud global es del 76%, en los casos más importantes (pacientes enfermos), la exactitud es tan solo del 50%.\n",
    "\n",
    "Otro punto a destacar en este ejemplo es que al haber sólo dos clases, el problema puede replantearse en términos de una sóla clase (diabético), de manera que 'class' = '0' representa un caso negativo (la muestra no pertenece a la clase) y 'class' = 1 constituye un caso positivo (la muestra pertenece a la clase). De esta manera, de los datos de prueba 80 no pertenecen a la clase (son negativos) y 50 si pertenecen a la clase (casos positivos). Entonces, la matriz de confusión puede interpretarse de la siguiente manera:\n",
    "\n",
    "* 74 resultados son 'verdaderos negativos'.\n",
    "* 6 resultados son 'falsos positivos' (clasificados erróneamente como positivos).\n",
    "* 25 resultados son 'verdaderos positivos'.\n",
    "* 25 resultados son 'falsos negativos' (clasificados erróneamente como negativos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas derivadas de la matriz de confusión\n",
    "\n",
    "La matriz de confusión permite definir una variedad de medidas de calidad en la clasificación (o en la predicción). \n",
    "\n",
    "Dada la matriz de confusión:\n",
    "\n",
    "$$\\mathbf{M} = \n",
    "\\begin{bmatrix}\n",
    "    M_{11}       & M_{12} & M_{13} & \\dots & M_{1n} \\\\\n",
    "    M_{21}       & M_{22} & M_{23} & \\dots & M_{2n} \\\\\n",
    "    \\vdots \\\\\n",
    "    M_{n1}       & M_{n2} & M_{n3} & \\dots & M_{nn}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Se definen los siguientes conceptos:\n",
    "\n",
    "* **Verdaderos positivos de la clase $i$**. Es la cantidad de elementos pertenecientes a la clase $i$ que fueron identificados correctamente:<br>\n",
    "$$Vp_i = M_{i,\\ i}$$<br>\n",
    "\n",
    "* **Falsos positivos de la clase $i$**. Es el número de elementos clasificados en la clase $i$ que en realidad pertenecen a la clase $j\\ne i$:<br>\n",
    "$$Fp_i = \\sum_{j\\ne i} M_{j,\\ i}$$\n",
    "también se le conoce como *Error tipo I* o *falsa alarma*<br><br>\n",
    "\n",
    "* **Verdaderos negativos de la clase $i$**. Es el número de elementos ajenos a la clase $i$ que fueron clasificados como negativos, o como pertenecientes a alguna otra clase $j\\ne i$, si hay más de dos clases:<br><br>\n",
    "$$Vn_i = \\sum_{k\\ne i,\\ j\\ne i} M_{k,\\ j}$$ <br>\n",
    "\n",
    "* **Falsos negativos de la clase $i$**. Es el número de elementos pertenecientes a la clase $i$ que fueron clasificados, erróneamente, en otra clase $j\\ne i$:<br>\n",
    "$$Fn_i = \\sum_{i\\ne j} M_{i,\\ j}$$\n",
    "Es también llamado *Error de tipo II* o *desacierto* (*miss*).<br><br>\n",
    "\n",
    "Y a partir de estos conceptos, se define una variedad de medidas de calidad, entre las que se encuentran las siguientes:\n",
    "\n",
    "* **Exactitud (*accuracy*)**. Es la proporción de predicciones correctas sobre el total de elementos en la muestra:<br><br>\n",
    "$$Acc = \\frac{\\sum Vp_i}{\\sum N_i}$$<br>\n",
    "siendo $N_i$ el número de elementos en la clase $i$. También se le conoce como *veracidad*.<br><br>\n",
    "\n",
    "* **Valor predictivo positivo de la clase $i$** o **Precisión de la clase $i$**. Es la proporción de verdaderos positivos de una clase con respecto al total de elementos clasificados como pertenecientes a la clase:<br><br>\n",
    "$$Vpp_i = \\frac{Vp_i}{Vp_i + Fp_i}$$<br>\n",
    "\n",
    "* **Valor predictivo negativo**. Es la proporción de falsos positivos en una clase, con respecto al total de elementos clasificados como no pertenecientes a la clase:<br>\n",
    "$$Vpn_i = \\frac{Fp_i}{Vn_i + Fn_i}$$<br>\n",
    "\n",
    "* **Sensibilidad (*recall*) de la clase $i$**. Es la proporción de elementos pertenecientes a la clase $i$ que fueron identificados correctamente:<br>\n",
    "$$Sen_i = \\frac{Vp_i}{N_i}$$<br>\n",
    "También se le suele llamar *tasa positiva verdadera*, *tasa de éxito* o *tasa de detección* y en inglés *recall*.<br><br>\n",
    "\n",
    "* **Especificidad de la clase $i$** o **Selectividad de la clase $i$**. Es la proporción de elementos no pertenecientes a la clase $i$ que fueron correctamente identificados como no pertenecientes a la clase $i$:<br><br>\n",
    "$$Esp_i = \\frac{Vn_i}{\\sum_{j\\ne i} N_j}$$\n",
    "Es también llamada *tasa negativa verdadera*.<br><br>\n",
    "\n",
    "* **Valor F1 de la clase $i$**. Es una medida compuesta de la exactitud de una prueba derivada a partir de la precisión y la sensibilidad.<br>\n",
    "$$F1_i = \\frac{Vpp_i\\times Sen_i}{Vpp_i + Sen_i}$$\n",
    "También es llamdo simplemente *valor F* o *escore F*.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analicemos algunas de estas medidas para nuestros ejemplos y modificamos los resultados de calificaciones para hacerlo más interesante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo calificaciones \n",
      "Exactitud:  1.0 \n",
      "Valor-F1:  [1. 1. 1.] \n",
      "...\n",
      "\n",
      "Salida esperada:    [1 0 0 0 1 1 0 2 2 1] \n",
      "Salida modificada:  [2 0 1 0 2 1 0 1 1 0] \n",
      "\n",
      "Matriz de confusión:\n",
      " [[3 1 0]\n",
      " [1 1 2]\n",
      " [0 2 0]] \n",
      "\n",
      "Exactitud:  0.4 \n",
      "\n",
      "Reporte:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         4\n",
      "           1       0.25      0.25      0.25         4\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.40      0.40      0.40        10\n",
      "   macro avg       0.33      0.33      0.33        10\n",
      "weighted avg       0.40      0.40      0.40        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as sm\n",
    "\n",
    "print(\"Ejemplo calificaciones\", \n",
    "      '\\nExactitud: ', sm.accuracy_score(test_expected_output, test_automatic_output), \n",
    "      '\\nValor-F1: ', sm.f1_score(test_expected_output, test_automatic_output, average=None),\n",
    "      '\\n...')\n",
    "\n",
    "dummy_aut = np.array([2, 0, 1, 0, 2, 1, 0, 1, 1, 0])\n",
    "print(\"\\nSalida esperada:   \", test_expected_output, \n",
    "      \"\\nSalida modificada: \", dummy_aut, \n",
    "      \"\\n\\nMatriz de confusión:\\n\", \n",
    "      confusion_matrix(test_expected_output, dummy_aut), \n",
    "      '\\n\\nExactitud: ', sm.accuracy_score(test_expected_output, dummy_aut), \n",
    "      \"\\n\\nReporte:\\n\", sm.classification_report(test_expected_output, dummy_aut))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión\n",
      " [[74  6]\n",
      " [25 25]] \n",
      "\n",
      "Reporte en el ejemplo diabetes:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83        80\n",
      "           1       0.81      0.50      0.62        50\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       130\n",
      "   macro avg       0.78      0.71      0.72       130\n",
      "weighted avg       0.77      0.76      0.75       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Matriz de confusión\\n\", \n",
    "      confusion_matrix(test_expected_output2, test_automatic_output2), \"\\n\")\n",
    "print(\"Reporte en el ejemplo diabetes:\\n\", \n",
    "      sm.classification_report(test_expected_output2, test_automatic_output2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
